{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c9836bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbea7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_STORAGE_CONNECTION_STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f7d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_urls_from_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        # Elimina comas y comillas extras de cada línea\n",
    "        urls = [line.strip().rstrip(',').replace(\"'\", \"\").replace('\"', '') for line in file if line.strip()]\n",
    "    return urls\n",
    "\n",
    "def correct_json_format(json_text):\n",
    "    corrected_text = re.sub(r'\"\\s*([^\"]+?)\\s*\"\\s*:\\s*\"(https?://[^\"]+)\"\\s*\"(\\w+)\"', r'\"\\1\": \"\\2\", \"\\3\"', json_text)\n",
    "    return corrected_text\n",
    "\n",
    "def extract_categories(url):\n",
    "    # Eliminar 'https://' y dividir la URL en partes para identificar los segmentos\n",
    "    parts = url.replace('https://www.dia.es/', '').split('/')\n",
    "    \n",
    "    # La categoría se encuentra en el primer segmento después del dominio\n",
    "    categoria = parts[0] if len(parts) > 0 else 'Sin categoría'\n",
    "    \n",
    "    # La subcategoría se encuentra en el segundo segmento\n",
    "    subcategoria = parts[1] if len(parts) > 1 else 'Sin subcategoría'\n",
    "    \n",
    "    return categoria, subcategoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc72470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read URLs from file\n",
    "urls = read_urls_from_file('urls.txt')\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/109.0'}\n",
    "base_url = 'https://www.dia.es'\n",
    "all_unique_links = set()\n",
    "\n",
    "# Extract unique links\n",
    "for url in urls:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        category_segment = url.split('/')[-2]\n",
    "        # Extract and adjust links to ensure they are absolute\n",
    "        for a in soup.find_all('a', href=True):\n",
    "            href = a['href']\n",
    "            if href.startswith('/'):\n",
    "                href = base_url + href  # Converts relative links to absolute\n",
    "            # Check if URL does not contain 'sort' in the last segment\n",
    "            if href.startswith(base_url) and category_segment in href and 'sort' not in href.split('/')[-1]:\n",
    "                all_unique_links.add(href)\n",
    "\n",
    "# Convert set to list\n",
    "all_unique_links = list(all_unique_links)\n",
    "\n",
    "productos = []\n",
    "precios = []\n",
    "categorias = []\n",
    "subcategorias = []\n",
    "\n",
    "# Scrape product details\n",
    "for url in all_unique_links:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        script = soup.find('script', type='application/ld+json')\n",
    "        if script:\n",
    "            corrected_json_text = correct_json_format(script.text)\n",
    "            try:\n",
    "                data = json.loads(corrected_json_text)\n",
    "                nombre_producto = data.get('name', 'Nombre no disponible')\n",
    "                offers = data.get('offers', {})\n",
    "                precio_producto = offers.get('price', 'Precio no disponible')\n",
    "                \n",
    "                categoria, subcategoria = extract_categories(url)\n",
    "                \n",
    "                productos.append(nombre_producto)\n",
    "                precios.append(precio_producto)\n",
    "                categorias.append(categoria)\n",
    "                subcategorias.append(subcategoria)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON from URL: {url}\")\n",
    "                print(f\"Error message: {e}\")\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Categoría': categorias,\n",
    "    'Subcategoría': subcategorias,\n",
    "    'Producto': productos,\n",
    "    'Precio': precios\n",
    "})\n",
    "\n",
    "csv_filename = f'productos_precios_categorias_{datetime.now().strftime(\"%Y_%m_%d\")}.csv'\n",
    "df.to_csv(csv_filename, index=False, sep=';', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22dfd863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File productos_precios_categorias_2024_05_22.csv uploaded to Azure Blob Storage successfully.\n"
     ]
    }
   ],
   "source": [
    "# Add a date column in Spanish format (dd/mm/yyyy)\n",
    "current_date = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "df['Fecha'] = current_date\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = f'productos_precios_categorias_{datetime.now().strftime(\"%Y_%m_%d\")}.csv'\n",
    "df.to_csv(csv_filename, index=False, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Azure Blob Storage details\n",
    "connect_str = AZURE_STORAGE_CONNECTION_STRING  # Reemplaza con tu cadena de conexión de Azure Blob Storage\n",
    "container_name = \"scrapingdia\"\n",
    "\n",
    "# Create the BlobServiceClient object\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "# Create a blob client\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=csv_filename)\n",
    "\n",
    "# Upload the created file\n",
    "with open(csv_filename, \"rb\") as data:\n",
    "    blob_client.upload_blob(data, overwrite=True)\n",
    "\n",
    "print(f\"File {csv_filename} uploaded to Azure Blob Storage successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
